{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation of the whole dataset using previously built U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Quadro P1000 (UUID: GPU-337a71bd-41de-e1d4-25dd-4ef2bc95668d)\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KC2XTyM3LRxh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q scikit-image\n",
    "!pip install -q pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "4Go4dbW1K9Xd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import skimage as ski\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2\n",
    "import os\n",
    "os.chdir(\"/tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0dA5xblx205c"
   },
   "outputs": [],
   "source": [
    "def crop(img, h, w):\n",
    "    \"\"\"Crops the image to match with specified height and width values\n",
    "\n",
    "    Args:\n",
    "        img (ndarray): image name\n",
    "        h (int): wanted number of pixels for height\n",
    "        w (int): wanted number of pixels for width\n",
    "\n",
    "    Returns:\n",
    "        img (ndarray): cropped image\n",
    "    \"\"\"\n",
    "    diff_h = img.shape[0] - h\n",
    "    diff_w = img.shape[1] - w\n",
    "    if diff_h > 0:\n",
    "        if diff_h%2 == 0:        \n",
    "            img = img[diff_h//2:img.shape[0] - diff_h//2, :]\n",
    "        else:\n",
    "            img = img[diff_h//2 + 1:img.shape[0] - diff_h//2, :]\n",
    "    if diff_w > 0:\n",
    "        if diff_w%2 == 0:\n",
    "            img = img[:, diff_w//2:img.shape[1] - diff_w//2]\n",
    "        else:\n",
    "            img = img[:, diff_w//2 + 1:img.shape[1] - diff_w//2]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZN4nnEkzClFp"
   },
   "outputs": [],
   "source": [
    "def resize_padding(image, RGB, h_target, w_target):\n",
    "    \"\"\"Adds some padding to an image to correspond to specified height and width\n",
    "\n",
    "    Args:\n",
    "        image (ndarray): image name\n",
    "        RGB (boolean): True if RGB (3 channels), False if greyscale\n",
    "        h_target (int): wanted number of pixels for height\n",
    "        w_target (int): wanted number of pixels for width\n",
    "    \n",
    "    Returns:\n",
    "        result (ndarray): padded image\n",
    "    \"\"\"\n",
    "\n",
    "    h, w = image.shape[0:2]\n",
    "    if h_target < h or w_target < w:\n",
    "        print(\"Specified dimensions smaller than the input image\")\n",
    "        return None\n",
    "        \n",
    "    delta_h = h_target - h\n",
    "    delta_w = w_target - w\n",
    "\n",
    "    pad_up = delta_h//2\n",
    "    pad_down = h_target - h - pad_up\n",
    "    pad_left = delta_w//2\n",
    "    pad_right = w_target - w - pad_left\n",
    "\n",
    "    if RGB:\n",
    "        return cv2.copyMakeBorder(image, pad_up, pad_down, pad_left, pad_right, \n",
    "                                  cv2.BORDER_CONSTANT, value = [255,255,255])\n",
    "    return cv2.copyMakeBorder(image, pad_up, pad_down, pad_left, pad_right, \n",
    "                              cv2.BORDER_CONSTANT, value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_vertical(top_img, bot_img, overlap):\n",
    "    \"\"\"Merges 2 patches of 512*512 pixels each\n",
    "\n",
    "    Args:\n",
    "        top_img (ndarray): patch corresponding to the top of the image\n",
    "        bot_img (ndarray): patch corresponding to the bottom of the image\n",
    "        overlap (int): number of pixels on which the 2 patches overlap\n",
    "\n",
    "    Returns:\n",
    "        full_img (ndarray): image resulting from the coupling of the 2 patches\n",
    "    \"\"\"\n",
    "    top = top_img[0:top_img.shape[0] - overlap, :]\n",
    "    bot = bot_img[bot_img.shape[0] - top.shape[0]:, :]\n",
    "    mid_top = top_img[top_img.shape[0] - overlap:top_img.shape[0], :]       \n",
    "    mid_bot = bot_img[0:overlap, :]\n",
    "\n",
    "    full_img = cv2.vconcat([top, mid_top])\n",
    "    full_img = cv2.vconcat([full_img, bot])\n",
    "\n",
    "    for i in range(1, 10):\n",
    "      full_img[512 - (i-1),:] = i*.1*top_img[512 - i,:] + (1 - i*.1)*bot_img[overlap - (i-1),:]\n",
    "    \n",
    "    return full_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_coef(y_true, y_pred):\n",
    "    \"\"\"Computes Jaccard score between ground truth and segmented image\n",
    "\n",
    "    Args:\n",
    "        y_true (ndarray): ground truth\n",
    "        y_pred (ndarray): segmented image\n",
    "\n",
    "    Returns:\n",
    "        float: Jaccard score\n",
    "    \"\"\"\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    \n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jaccard_coef() function is taken from: <br>\n",
    "https://github.com/bnsreenu/python_for_microscopists/blob/2c2b120fec17d8686572719916920bc05e3288f8/207-simple_unet_model_with_jacard.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "K1xUqzRTI1T-"
   },
   "outputs": [],
   "source": [
    "loss = \"categorical_crossentropy\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('notebooks/unet3.hdf5',\n",
    "                                  custom_objects = {\"categorical_crossentropy\":loss, \"jaccard_coef\":jaccard_coef})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model prediction on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_unet(img):\n",
    "    \"\"\"Uses our U-Net network to segment a given image\n",
    "\n",
    "    Args:\n",
    "        img (ndarray): image to be segmented\n",
    "\n",
    "    Returns:\n",
    "        img_seg (ndarray): probability map resulting from segmentation\n",
    "    \"\"\"\n",
    "    or_shape = img.shape\n",
    "    if or_shape[0] > 768:\n",
    "        img = crop(img, 768, img.shape[1])\n",
    "    elif or_shape[1] > 512:\n",
    "        img = crop(img, img.shape[0], 512)\n",
    "        \n",
    "    img_padded = np.array(resize_padding(img, True, 768, 512))\n",
    "    patches = np.array([img_padded[256:, :]] +  [img_padded[0:512, :]])\n",
    "    predicted = [np.squeeze(model.predict(np.expand_dims(im, 0))) for im in patches]\n",
    "    img_seg = merge_vertical(predicted[1], predicted[0], abs(img_padded.shape[0] - 2*512))\n",
    "    img_seg = crop(img_seg, or_shape[0], or_shape[1])\n",
    "    return img_seg[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ski.io.imread_collection('datasets/Dossiers_Mildiou_Maj2023/*').files\n",
    "\n",
    "for folder in folders:\n",
    "    if os.path.exists(folder + '/Segment_Unet'): \n",
    "        shutil.rmtree(folder + '/Segment_Unet')\n",
    "    Images = ski.io.imread_collection(folder +  '/Recalibrated_CPD/*').files\n",
    "    Visible = []\n",
    "    for im in Images:\n",
    "        if not any([x in im for x in ['Fv', 'Fo', 'Fm', 'FvFm', 'error']]):   \n",
    "            Visible.append(im)\n",
    "    Visible = sorted(Visible, key=str.casefold, reverse=True)  \n",
    "    \n",
    "    os.mkdir(folder + '/Segment_Unet')  \n",
    "    for im_path in Visible:\n",
    "        im = ski.io.imread(im_path)\n",
    "        res = segment_unet(im)\n",
    "        \n",
    "        #Post-processing step:\n",
    "        \n",
    "        if len(Visible) == 4 and \"_J5_\" not in im_path or len(Visible) == 3 and \"_J4_\" not in im_path:  \n",
    "            for i in range(res.shape[0]):\n",
    "                for j in range(res.shape[1]):\n",
    "                    if res[i, j] > res_upcoming_day[i, j]:\n",
    "                        res[i, j] = res_upcoming_day[i, j]\n",
    "        res_upcoming_day = res\n",
    "            \n",
    "        ski.io.imsave(folder + '/Segment_Unet' + '/P_map_' + im_path.rsplit('/', 1)[-1], res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
